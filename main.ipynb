{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/rasbt/machine-learning-book/blob/main/ch18/ch18_part2.py"
      ],
      "metadata": {
        "id": "5eJEe3o0chMa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-1.12.0+cpu.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGn95vpM8EGg",
        "outputId": "6b377fc5-8c5c-49e9-80f8-4cc44e3ad274"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.0+cpu.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcpu/torch_scatter-2.0.9-cp37-cp37m-linux_x86_64.whl (286 kB)\n",
            "\u001b[K     |████████████████████████████████| 286 kB 25.1 MB/s \n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcpu/torch_sparse-0.6.15-cp37-cp37m-linux_x86_64.whl (641 kB)\n",
            "\u001b[K     |████████████████████████████████| 641 kB 47.8 MB/s \n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcpu/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl (311 kB)\n",
            "\u001b[K     |████████████████████████████████| 311 kB 25.7 MB/s \n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-1.12.0%2Bcpu/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 66.4 MB/s \n",
            "\u001b[?25hCollecting torch-geometric\n",
            "  Downloading torch_geometric-2.1.0.post1.tar.gz (467 kB)\n",
            "\u001b[K     |████████████████████████████████| 467 kB 31.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.7.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.1.0.post1-py3-none-any.whl size=689859 sha256=c7b3588b7a440acd23bd60c87becfb04bab72ea39a69a54aff2ee5f2e4c0a535\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/cb/43/f7f2e472de4d7cff31bceddadc36d634e1e545fbc17961c282\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-spline-conv, torch-sparse, torch-scatter, torch-geometric, torch-cluster\n",
            "Successfully installed torch-cluster-1.6.0 torch-geometric-2.1.0.post1 torch-scatter-2.0.9 torch-sparse-0.6.15 torch-spline-conv-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics # r2 score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRYQHVV8Il-p",
        "outputId": "d9699fb1-ec56-402e-cd1c-fc86009b15e0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.10.0-py3-none-any.whl (529 kB)\n",
            "\u001b[K     |████████████████████████████████| 529 kB 26.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.12.1+cu113)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CmF00hlq7_RZ"
      },
      "outputs": [],
      "source": [
        "import utils\n",
        "import torch\n",
        "from pandas import read_csv, DataFrame as df\n",
        "from numpy import array as arr, expand_dims, arange, corrcoef as corr, where, isnan\n",
        "from ast import literal_eval as lev\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from warnings import filterwarnings as fw; fw(\"ignore\")\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn import NNConv, global_add_pool\n",
        "import math\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from torchmetrics.functional import r2_score # library utk r2 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Sb2fnzG_7_Rc"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 42\n",
        "EMBEDDING_DIM = 5\n",
        "BATCH_SIZE = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CZ0RN1917_Rd"
      },
      "outputs": [],
      "source": [
        "THRESHOLD = .95\n",
        "WINDOW_SIZE = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "D1_mGoiZ7_Rd"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = \"./dataset/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "k2IqVxBx7_Re"
      },
      "outputs": [],
      "source": [
        "def load_dataset(path : str = DATASET_PATH, partial : int = None, *args, **kwargs) -> tuple:\n",
        "    big_dataset = read_csv(path + \"gp_table.csv\")\n",
        "    \n",
        "    if partial is not None:\n",
        "        big_dataset = big_dataset[:partial]\n",
        "    \n",
        "    x = arr([lev(i) for i in big_dataset['snps']]) # convert string of list into literal list\n",
        "    y = arr(big_dataset['rice_yield'])\n",
        "    print(\"============ Raw Data ============\")\n",
        "    print(\"x data dim: {}\".format(x.shape))\n",
        "    print(\"y data dim: {}\".format(y.shape), end=\"\\n\\n\")\n",
        "\n",
        "    # split dataset\n",
        "    x_train, x_test, y_train, y_test = tts(x, y, test_size=.3, random_state=RANDOM_SEED)\n",
        "    x_test, x_val, y_test, y_val = tts(x_test, y_test, test_size=.5, random_state=RANDOM_SEED)\n",
        "\n",
        "    print(\"========= Processed Data =========\")\n",
        "    print(\"x_train: {}, y_train: {}\".format(len(x_train), len(y_train)))\n",
        "    print(\"x_valid: {}, y_valid: {}\".format(len(x_val), len(y_val)))\n",
        "    print(\"x_test: {}, y_test: {}\".format(len(x_test), len(y_test)))\n",
        "\n",
        "    return (x_train, y_train), (x_val, y_val), (x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CWh32Qrm7_Rf"
      },
      "outputs": [],
      "source": [
        "def chr_pos_list(path : str = DATASET_PATH, *args, **kwargs) -> dict:\n",
        "    imputed_snps_data = read_csv(path + \"ind-rg-snps.csv\")\n",
        "    cleaned_snps = df(imputed_snps_data.columns[2:], columns=[\"snps\"])\n",
        "    \n",
        "    chr_data = read_csv(path + \"ind-rg-chrpos.csv\", index_col=0)\n",
        "    chr_data.insert(len(chr_data.columns), \"snps\", list(map(lambda x, y: x + \"_\" + y, chr_data.id, chr_data.ref)))\n",
        "    \n",
        "    snps_chrpos = chr_data.merge(cleaned_snps, on=[\"snps\"], how=\"right\")\n",
        "    all_chr_list = torch.tensor(snps_chrpos.chr.values, dtype=torch.long)\n",
        "    all_pos_list = torch.tensor(snps_chrpos.pos.values, dtype=torch.long)\n",
        "    return {\"chr\" : all_chr_list, \"pos\" : all_pos_list}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fhHHENZe7_Rg"
      },
      "outputs": [],
      "source": [
        "snps_chr_pos = chr_pos_list()\n",
        "all_chr_list, all_pos_list = snps_chr_pos[\"chr\"], snps_chr_pos[\"pos\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6O87cIj7_Rh",
        "outputId": "ef4438a1-db21-436b-a311-8c53031872de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============ Raw Data ============\n",
            "x data dim: (100, 1232)\n",
            "y data dim: (100,)\n",
            "\n",
            "========= Processed Data =========\n",
            "x_train: 70, y_train: 70\n",
            "x_valid: 15, y_valid: 15\n",
            "x_test: 15, y_test: 15\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_val, y_val), (x_test, y_test) = load_dataset(partial=100, apply_pca=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "x9jDIToS7_Ri"
      },
      "outputs": [],
      "source": [
        "def vectorized_sliding_windows(data, max_len : int, window_size : int = WINDOW_SIZE, start : int = 0) -> arr:\n",
        "    max_len -= window_size-1\n",
        "    sub_windows = (\n",
        "        start +\n",
        "        expand_dims(arange(window_size), 0) +\n",
        "        expand_dims(arange(max_len), 0).T\n",
        "    )\n",
        "    \n",
        "    return arr(data)[sub_windows]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rZKA7Qw97_Rj"
      },
      "outputs": [],
      "source": [
        "def create_edge_index(\n",
        "    data,\n",
        "    thresh : float = THRESHOLD,\n",
        "    step_decay : float = .02,\n",
        "    lower_bound_edges : int = 20,\n",
        "    *args, **kwargs\n",
        ") -> dict:\n",
        "    edges = []\n",
        "    count_step_decay = 0\n",
        "    corr_vals= []\n",
        "    \n",
        "    while len(edges) <= lower_bound_edges:\n",
        "        corr_vals= []\n",
        "        allel = df(corr(vectorized_sliding_windows(data, len(data))))\n",
        "        allel = allel.mask(allel < thresh) # filter: mark column as NaN if it is below the threshold\n",
        "        \n",
        "        edges = [(x, allel.columns[y]) for x, y in zip(*where(~isnan(allel.values)))] # get coord where the value is not NaN\n",
        "        edges = [i for i in edges if i[0] != i[1]] # remove duplicates (in diagonal), e.g., (0, 0), (1, 1), (2, 2)\n",
        "\n",
        "        \n",
        "        # corr_vals = [x for x in math.isnan(allel.values)]\n",
        "        for i in range(0, len(allel.values)):\n",
        "          for j in range(0, len(allel.values[i])):\n",
        "            if i!=j and math.isnan(allel.values[i][j]) == False:\n",
        "              corr_vals.append(allel.values[i][j])\n",
        "\n",
        "        # corr_vals = [i for i in corr_vals if i[0] != i[1]]      \n",
        "\n",
        "        if len(edges) <= lower_bound_edges:\n",
        "            thresh = round(thresh-step_decay, 2)\n",
        "            count_step_decay += 1\n",
        "\n",
        "    # print(corr_vals)\n",
        "    # print(edges)\n",
        "    # print(len(corr_vals))\n",
        "    # print(len(edges))\n",
        "    idx_source, idx_dest = [idx[0] for idx in edges], [idx[1] for idx in edges]\n",
        "    # print(len(idx_source))\n",
        "    edge_index = torch.tensor([idx_source, idx_dest], dtype=torch.long)\n",
        "    return {\"edge_index\" : edge_index, \"corr_vals\": corr_vals, \"total_conn\" : len(edges), \"treshold_used\" : thresh, \"count_step_decay\" : count_step_decay}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5itS91-U7_Rl"
      },
      "outputs": [],
      "source": [
        "def create_node_index(\n",
        "    snp_data,\n",
        "    snp_vocab : int = 3,\n",
        "    chr_data : torch.Tensor = all_chr_list,\n",
        "    chr_vocab : int = max(all_chr_list).item()+1,\n",
        "    pos_data : torch.Tensor = all_pos_list,\n",
        "    pos_vocab : int = max(all_pos_list).item()+1,\n",
        "    dim : int = EMBEDDING_DIM,\n",
        "    *args, **kwargs\n",
        ") -> dict:\n",
        "    embedding = torch.nn.Embedding(3, dim)\n",
        "    node_index = embedding(torch.from_numpy(snp_data))\n",
        "    \n",
        "    chr_embedding = torch.nn.Embedding(chr_vocab, dim)\n",
        "    node_index += chr_embedding(chr_data)\n",
        "    \n",
        "    pos_embedding = torch.nn.Embedding(pos_vocab, dim)\n",
        "    node_index += pos_embedding(pos_data)\n",
        "    return {\"node_index\" : node_index, \"shape\" : node_index.shape}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_edge_attr(\n",
        "    corr_vals,\n",
        "    *args, **kwargs\n",
        ") -> dict:\n",
        "\n",
        "    cor_val_labels = []\n",
        "    for val in corr_vals:\n",
        "      if val == 0: \n",
        "        # print(f'{val} No Correlation')\n",
        "        cor_val_labels.append(0)\n",
        "      elif val <0.6:\n",
        "        # print(f'{val} Less Correlation')\n",
        "        cor_val_labels.append(1)\n",
        "      elif val < 1:\n",
        "        # print(f'{val} Correlated')\n",
        "        cor_val_labels.append(2)\n",
        "      else:\n",
        "        # print(f'{val} Highly Correlated')\n",
        "        cor_val_labels.append(3)   \n",
        "\n",
        "    cor_val_labels = torch.tensor(cor_val_labels)\n",
        "    edge_attribute = F.one_hot(cor_val_labels, num_classes=4).to(torch.float)\n",
        "\n",
        "    return {\"edge_attribute\" : edge_attribute, \"shape\" : edge_attribute.shape}"
      ],
      "metadata": {
        "id": "UofnpzVYRKl6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Lhi9GssF7_Rm"
      },
      "outputs": [],
      "source": [
        "def create_dataloader(x, label, batch_size : int = BATCH_SIZE, *args, **kwargs):\n",
        "    data = []\n",
        "    for i in zip(x, label):\n",
        "        snp_data, yield_data = i[0], i[1]\n",
        "        node = create_node_index(snp_data)\n",
        "        edge = create_edge_index(snp_data)\n",
        "        # print(edge[\"corr_vals\"])\n",
        "        edge_attribute = create_edge_attr(edge[\"corr_vals\"])\n",
        "        label = torch.tensor(i[1], dtype=torch.long)\n",
        "        data.append(Data(x=node[\"node_index\"], edge_index=edge[\"edge_index\"], y=label, edge_attr= edge_attribute[\"edge_attribute\"] ))\n",
        "        \n",
        "        del snp_data\n",
        "        del yield_data\n",
        "        del node\n",
        "        del edge\n",
        "        del label\n",
        "        \n",
        "    return DataLoader(data, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# valid_dataloader = create_dataloader(x_val[:1], y_val[:1])"
      ],
      "metadata": {
        "id": "zmu7gtqqJALN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "T5Dsbovi7_Rn"
      },
      "outputs": [],
      "source": [
        "train_dataloader = create_dataloader(x_train[:3], y_train[:3])\n",
        "valid_dataloader = create_dataloader(x_val[:1], y_val[:1])\n",
        "test_dataloader = create_dataloader(x_test[:1], y_test[:1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(test_dataloader)\n",
        "for data in test_dataloader:\n",
        "  print(data.y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7PVHmWkTC8M",
        "outputId": "5b70adfd-f74d-4219-e812-6e53b13096c3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "iM-mqz6Q7_Rn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad1444b3-f58f-48d2-f06e-5be99379fd2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train\n",
            "DataBatch(x=[2464, 5], edge_index=[2, 88], edge_attr=[88, 4], y=[2], batch=[2464], ptr=[3])\n",
            "DataBatch(x=[1232, 5], edge_index=[2, 26], edge_attr=[26, 4], y=[1], batch=[1232], ptr=[2])\n",
            "\n",
            "valid\n",
            "DataBatch(x=[1232, 5], edge_index=[2, 52], edge_attr=[52, 4], y=[1], batch=[1232], ptr=[2])\n",
            "\n",
            "test\n",
            "DataBatch(x=[1232, 5], edge_index=[2, 32], edge_attr=[32, 4], y=[1], batch=[1232], ptr=[2])\n"
          ]
        }
      ],
      "source": [
        "print(\"train\")\n",
        "for i in train_dataloader:\n",
        "    print(i)\n",
        "print()\n",
        "print(\"valid\")\n",
        "for i in valid_dataloader:\n",
        "    print(i)\n",
        "print()\n",
        "print(\"test\")\n",
        "for i in test_dataloader:\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ExampleNet(torch.nn.Module):\n",
        "    def __init__(self,num_node_features, num_edge_features):\n",
        "        super().__init__()\n",
        "        conv1_net = nn.Sequential(nn.Linear(num_edge_features, 32),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Linear(32, num_node_features*32))\n",
        "        conv2_net = nn.Sequential(nn.Linear(num_edge_features,32),\n",
        "                                  nn.ReLU(),\n",
        "                                  nn.Linear(32, 32*16))\n",
        "        self.conv1 = NNConv(num_node_features, 32, conv1_net)\n",
        "        self.conv2 = NNConv(32, 16, conv2_net)\n",
        "        self.fc_1 = nn.Linear(16, 32)\n",
        "        self.out = nn.Linear(32, 1)\n",
        "        \n",
        "    def forward(self, data):\n",
        "        batch, x, edge_index, edge_attr=data.batch, data.x, data.edge_index, data.edge_attr\n",
        "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
        "        x = F.relu(self.conv2(x, edge_index, edge_attr))\n",
        "        x = global_add_pool(x,batch)\n",
        "        x = F.relu(self.fc_1(x))\n",
        "        output = self.out(x)\n",
        "        return output"
      ],
      "metadata": {
        "id": "IDeEb1pYJNLD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_node_feats, num_edge_feats = 5, 4\n",
        "epochs = 4\n",
        "net = ExampleNet(num_node_feats, num_edge_feats)\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
        "epochs = 4\n",
        "target_idx = 1 # index position of the polarizability label\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# device = torch.device(\"cpu\")\n",
        "net.to(device)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "for total_epochs in range(epochs):\n",
        "    epoch_loss = 0\n",
        "    epoch_r2 = 0\n",
        "    total_graphs = 0\n",
        "    net.train()\n",
        "    for batch in train_dataloader:\n",
        "        batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = net(batch)\n",
        "        # print(output.flatten())\n",
        "        # print(batch.y)\n",
        "        loss = F.mse_loss(output, batch.y)\n",
        "        # train_r2 = r2_score(output.flatten(), batch.y) # r2 score -> disini output harus di flatten agar tensor shapenya sama dengan y\n",
        "\n",
        "        loss_float = torch.tensor(loss, dtype=torch.float, requires_grad = True)\n",
        "        loss_float.retain_grad()\n",
        "        loss_float.backward()\n",
        "        epoch_loss += loss.item()\n",
        "        total_graphs += batch.num_graphs\n",
        "        optimizer.step()\n",
        "        torch.save(net, 'tes.pt') # untuk save model\n",
        "    \n",
        "    train_avg_loss = epoch_loss / total_graphs\n",
        "    val_loss = 0\n",
        "    val_r2 = 0\n",
        "    total_graphs = 0\n",
        "    net = torch.load('tes.pt') # load model untuk validasi\n",
        "    net.eval()\n",
        "    for batch in valid_dataloader:\n",
        "        batch.to(device)\n",
        "        output = net(batch)\n",
        "        loss = F.mse_loss(output,batch.y)\n",
        "        # val_r2 = r2_score(output.flatten(), batch.y) # r2 score -> disini output harus di flatten agar tensor shapenya sama dengan y\n",
        "        val_loss += loss.item()\n",
        "        total_graphs += batch.num_graphs\n",
        "    val_avg_loss = val_loss / total_graphs\n",
        "    \n",
        "    \n",
        "    print(f\"Epochs: {total_epochs} | epoch avg. loss: {train_avg_loss:.2f} | epoch avg. r2: {train_avg_loss:.2f} | validation avg. loss: {val_avg_loss:.2f} | | validation avg. r2: {val_avg_loss:.2f}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "PRmS5s-RJ_zz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e07022b-efe2-41ae-96d8-57e3458488a9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 0 | epoch avg. loss: 1146.26 | epoch avg. r2: 1146.26 | validation avg. loss: 2459.64 | | validation avg. r2: 2459.64\n",
            "\n",
            "Epochs: 1 | epoch avg. loss: 1015.95 | epoch avg. r2: 1015.95 | validation avg. loss: 2459.64 | | validation avg. r2: 2459.64\n",
            "\n",
            "Epochs: 2 | epoch avg. loss: 1146.26 | epoch avg. r2: 1146.26 | validation avg. loss: 2459.64 | | validation avg. r2: 2459.64\n",
            "\n",
            "Epochs: 3 | epoch avg. loss: 720.23 | epoch avg. r2: 720.23 | validation avg. loss: 2459.64 | | validation avg. r2: 2459.64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = torch.load('tes.pt') # load model untuk testing\n",
        "net.eval()\n",
        "predictions = []\n",
        "real = []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    print(batch.y)\n",
        "    output = net(batch.to(device))\n",
        "    predictions.append(output.detach().cpu().numpy())\n",
        "    real.append(batch.y.detach().cpu().numpy())\n",
        "\n",
        "predictions = np.concatenate(predictions)\n",
        "real = np.concatenate(real)"
      ],
      "metadata": {
        "id": "cmGLs9fgERbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68a0d9e9-40a0-41a0-ded4-65dd1df5e0ad"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(predictions))\n",
        "print(len(real))"
      ],
      "metadata": {
        "id": "VU6oUOJfEs-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4811ecb5-d39c-401e-ef26-7077b406c354"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(real,predictions)\n",
        "plt.ylabel('Predicted isotropic polarizability')\n",
        "plt.xlabel('Isotropic polarizability')"
      ],
      "metadata": {
        "id": "eVuszYoSci8F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "15e3b26c-9f26-45ec-e79f-58e177735688"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Isotropic polarizability')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4hHTPUf17_Ro"
      },
      "outputs": [],
      "source": [
        "# del train_dataloader"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "gnn-venv",
      "language": "python",
      "name": "gnn-venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}